{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracknet.model import GridTrackNetModel\n",
    "from tracknet.dataset import TrackNet\n",
    "from torchinfo import summary\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmrmorais\u001b[0m (\u001b[33mmrmorais-home\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_loss</td><td>▂▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>6</td></tr><tr><td>train_loss</td><td>0.0084</td></tr><tr><td>val_acc</td><td>0</td></tr><tr><td>val_loss</td><td>0.08465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandb_train_mse</strong> at: <a href='https://wandb.ai/mrmorais-home/GridTrackNet/runs/w44xjpm4' target=\"_blank\">https://wandb.ai/mrmorais-home/GridTrackNet/runs/w44xjpm4</a><br> View project at: <a href='https://wandb.ai/mrmorais-home/GridTrackNet' target=\"_blank\">https://wandb.ai/mrmorais-home/GridTrackNet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250401_231238-w44xjpm4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/grid-track-net/wandb/run-20250401_232747-5q8td7pf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mrmorais-home/GridTrackNet/runs/5q8td7pf' target=\"_blank\">wandb_train_l1_adam</a></strong> to <a href='https://wandb.ai/mrmorais-home/GridTrackNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mrmorais-home/GridTrackNet' target=\"_blank\">https://wandb.ai/mrmorais-home/GridTrackNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mrmorais-home/GridTrackNet/runs/5q8td7pf' target=\"_blank\">https://wandb.ai/mrmorais-home/GridTrackNet/runs/5q8td7pf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='GridTrackNet', name='wandb_train_l1_adam')\n",
    "\n",
    "model = GridTrackNetModel()\n",
    "\n",
    "wandb.watch(model, log_freq=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "GridTrackNetModel                        [10, 15, 27, 48]          --\n",
       "├─ConvBlock: 1-1                         [10, 64, 432, 768]        --\n",
       "│    └─Sequential: 2-1                   [10, 64, 432, 768]        --\n",
       "│    │    └─Conv2d: 3-1                  [10, 64, 432, 768]        8,704\n",
       "│    │    └─ReLU: 3-2                    [10, 64, 432, 768]        --\n",
       "│    │    └─BatchNorm2d: 3-3             [10, 64, 432, 768]        128\n",
       "├─ConvBlock: 1-2                         [10, 64, 432, 768]        --\n",
       "│    └─Sequential: 2-2                   [10, 64, 432, 768]        --\n",
       "│    │    └─Conv2d: 3-4                  [10, 64, 432, 768]        36,928\n",
       "│    │    └─ReLU: 3-5                    [10, 64, 432, 768]        --\n",
       "│    │    └─BatchNorm2d: 3-6             [10, 64, 432, 768]        128\n",
       "├─MaxPool2d: 1-3                         [10, 64, 216, 384]        --\n",
       "├─ConvBlock: 1-4                         [10, 128, 216, 384]       --\n",
       "│    └─Sequential: 2-3                   [10, 128, 216, 384]       --\n",
       "│    │    └─Conv2d: 3-7                  [10, 128, 216, 384]       73,856\n",
       "│    │    └─ReLU: 3-8                    [10, 128, 216, 384]       --\n",
       "│    │    └─BatchNorm2d: 3-9             [10, 128, 216, 384]       256\n",
       "├─ConvBlock: 1-5                         [10, 128, 216, 384]       --\n",
       "│    └─Sequential: 2-4                   [10, 128, 216, 384]       --\n",
       "│    │    └─Conv2d: 3-10                 [10, 128, 216, 384]       147,584\n",
       "│    │    └─ReLU: 3-11                   [10, 128, 216, 384]       --\n",
       "│    │    └─BatchNorm2d: 3-12            [10, 128, 216, 384]       256\n",
       "├─MaxPool2d: 1-6                         [10, 128, 108, 192]       --\n",
       "├─ConvBlock: 1-7                         [10, 256, 108, 192]       --\n",
       "│    └─Sequential: 2-5                   [10, 256, 108, 192]       --\n",
       "│    │    └─Conv2d: 3-13                 [10, 256, 108, 192]       295,168\n",
       "│    │    └─ReLU: 3-14                   [10, 256, 108, 192]       --\n",
       "│    │    └─BatchNorm2d: 3-15            [10, 256, 108, 192]       512\n",
       "├─ConvBlock: 1-8                         [10, 256, 108, 192]       --\n",
       "│    └─Sequential: 2-6                   [10, 256, 108, 192]       --\n",
       "│    │    └─Conv2d: 3-16                 [10, 256, 108, 192]       590,080\n",
       "│    │    └─ReLU: 3-17                   [10, 256, 108, 192]       --\n",
       "│    │    └─BatchNorm2d: 3-18            [10, 256, 108, 192]       512\n",
       "├─MaxPool2d: 1-9                         [10, 256, 54, 96]         --\n",
       "├─ConvBlock: 1-10                        [10, 256, 54, 96]         --\n",
       "│    └─Sequential: 2-7                   [10, 256, 54, 96]         --\n",
       "│    │    └─Conv2d: 3-19                 [10, 256, 54, 96]         590,080\n",
       "│    │    └─ReLU: 3-20                   [10, 256, 54, 96]         --\n",
       "│    │    └─BatchNorm2d: 3-21            [10, 256, 54, 96]         512\n",
       "├─ConvBlock: 1-11                        [10, 256, 54, 96]         --\n",
       "│    └─Sequential: 2-8                   [10, 256, 54, 96]         --\n",
       "│    │    └─Conv2d: 3-22                 [10, 256, 54, 96]         590,080\n",
       "│    │    └─ReLU: 3-23                   [10, 256, 54, 96]         --\n",
       "│    │    └─BatchNorm2d: 3-24            [10, 256, 54, 96]         512\n",
       "├─ConvBlock: 1-12                        [10, 256, 54, 96]         --\n",
       "│    └─Sequential: 2-9                   [10, 256, 54, 96]         --\n",
       "│    │    └─Conv2d: 3-25                 [10, 256, 54, 96]         590,080\n",
       "│    │    └─ReLU: 3-26                   [10, 256, 54, 96]         --\n",
       "│    │    └─BatchNorm2d: 3-27            [10, 256, 54, 96]         512\n",
       "├─MaxPool2d: 1-13                        [10, 256, 27, 48]         --\n",
       "├─ConvBlock: 1-14                        [10, 512, 27, 48]         --\n",
       "│    └─Sequential: 2-10                  [10, 512, 27, 48]         --\n",
       "│    │    └─Conv2d: 3-28                 [10, 512, 27, 48]         1,180,160\n",
       "│    │    └─ReLU: 3-29                   [10, 512, 27, 48]         --\n",
       "│    │    └─BatchNorm2d: 3-30            [10, 512, 27, 48]         1,024\n",
       "├─ConvBlock: 1-15                        [10, 512, 27, 48]         --\n",
       "│    └─Sequential: 2-11                  [10, 512, 27, 48]         --\n",
       "│    │    └─Conv2d: 3-31                 [10, 512, 27, 48]         2,359,808\n",
       "│    │    └─ReLU: 3-32                   [10, 512, 27, 48]         --\n",
       "│    │    └─BatchNorm2d: 3-33            [10, 512, 27, 48]         1,024\n",
       "├─ConvBlock: 1-16                        [10, 512, 27, 48]         --\n",
       "│    └─Sequential: 2-12                  [10, 512, 27, 48]         --\n",
       "│    │    └─Conv2d: 3-34                 [10, 512, 27, 48]         2,359,808\n",
       "│    │    └─ReLU: 3-35                   [10, 512, 27, 48]         --\n",
       "│    │    └─BatchNorm2d: 3-36            [10, 512, 27, 48]         1,024\n",
       "├─Conv2d: 1-17                           [10, 15, 27, 48]          69,135\n",
       "├─Sigmoid: 1-18                          [10, 15, 27, 48]          --\n",
       "==========================================================================================\n",
       "Total params: 8,897,871\n",
       "Trainable params: 8,897,871\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 687.76\n",
       "==========================================================================================\n",
       "Input size (MB): 199.07\n",
       "Forward/backward pass size (MB): 12847.92\n",
       "Params size (MB): 35.59\n",
       "Estimated Total Size (MB): 13082.58\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(10, 15, 432, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adadelta, Adam\n",
    "import numpy as np\n",
    "from torch import cuda\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, val_loader):\n",
    "    device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "\n",
    "    corrects = []\n",
    "    losses = []\n",
    "\n",
    "    for _, (instances, label) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            label = label.permute(0, 1, 4, 2, 3).reshape(val_loader.batch_size, 3 * 5, 27, 48).to(device, dtype=torch.float32)\n",
    "\n",
    "            instances = instances.to(device, dtype=torch.float32)\n",
    "            outputs = model(instances)\n",
    "\n",
    "            loss = criterion(outputs, label)\n",
    "            losses.append(loss.item() * instances.size(0))\n",
    "\n",
    "            for i in range(val_loader.batch_size):\n",
    "                # Each 3 items is a grid confidence for 1 of 5 frames\n",
    "                for j in range(0, 15, 3):\n",
    "                    gt = np.argmax(label[i][j].flatten().cpu())\n",
    "                    gt_x, gt_y = np.unravel_index(gt, (27, 48))\n",
    "\n",
    "                    out = np.argmax(outputs[i][j].flatten().cpu())\n",
    "                    out_x, out_y = np.unravel_index(out, (27, 48))\n",
    "                    print(gt_x, out_x, gt_y, out_y)\n",
    "\n",
    "                    corrects.append(gt_x == out_x and gt_y == out_y)\n",
    "\n",
    "    acc = sum(corrects) / len(corrects)\n",
    "    avg_loss = np.average(losses)\n",
    "\n",
    "    return acc, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrackNet.__init__() missing 1 required positional argument: 'files'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m val_dataset = \u001b[43mTrackNet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcompiled_dataset\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m val_loader = DataLoader(val_dataset, batch_size=\u001b[32m10\u001b[39m)\n\u001b[32m      5\u001b[39m validate(model, val_loader)\n",
      "\u001b[31mTypeError\u001b[39m: TrackNet.__init__() missing 1 required positional argument: 'files'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val_dataset = TrackNet('compiled_dataset')\n",
    "val_loader = DataLoader(val_dataset, batch_size=10)\n",
    "validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, train_loader, val_loader, epochs = 50):\n",
    "    device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    # criterion = nn.MSELoss()\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = Adadelta(lr=1.0, params=model.parameters(), weight_decay=0.01)\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for instances, label in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            label = label.permute(0, 1, 4, 2, 3).reshape(train_loader.batch_size, 3 * 5, 27, 48).to(device, dtype=torch.float32)\n",
    "\n",
    "            instances = instances.to(device, dtype=torch.float32)\n",
    "            outputs = model(instances)\n",
    "\n",
    "            # print(outputs.shape, label.shape)\n",
    "\n",
    "            loss = criterion(outputs, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * instances.size(0)\n",
    "            total_samples += instances.size(0)\n",
    "\n",
    "            # print(loss)\n",
    "            wandb.log({ 'train_loss': loss })\n",
    "\n",
    "        avg_loss = running_loss / total_samples\n",
    "\n",
    "        val_acc, val_loss = validate(model, criterion, val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train Loss {avg_loss:.4f}, Val Acc={val_acc:.4f}, Val Loss={val_loss:.4f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['060.hdf5', '031.hdf5', '010.hdf5', '059.hdf5', '016.hdf5', '052.hdf5'],\n",
       " ['024.hdf5',\n",
       "  '013.hdf5',\n",
       "  '007.hdf5',\n",
       "  '061.hdf5',\n",
       "  '023.hdf5',\n",
       "  '006.hdf5',\n",
       "  '026.hdf5',\n",
       "  '030.hdf5',\n",
       "  '022.hdf5',\n",
       "  '001.hdf5',\n",
       "  '011.hdf5',\n",
       "  '036.hdf5',\n",
       "  '019.hdf5',\n",
       "  '000.hdf5',\n",
       "  '039.hdf5',\n",
       "  '018.hdf5',\n",
       "  '044.hdf5',\n",
       "  '005.hdf5',\n",
       "  '012.hdf5',\n",
       "  '037.hdf5',\n",
       "  '027.hdf5',\n",
       "  '015.hdf5',\n",
       "  '050.hdf5',\n",
       "  '047.hdf5',\n",
       "  '034.hdf5',\n",
       "  '035.hdf5',\n",
       "  '046.hdf5',\n",
       "  '054.hdf5',\n",
       "  '017.hdf5',\n",
       "  '028.hdf5',\n",
       "  '058.hdf5',\n",
       "  '003.hdf5',\n",
       "  '045.hdf5',\n",
       "  '025.hdf5',\n",
       "  '014.hdf5',\n",
       "  '032.hdf5',\n",
       "  '038.hdf5',\n",
       "  '041.hdf5',\n",
       "  '008.hdf5',\n",
       "  '049.hdf5',\n",
       "  '042.hdf5',\n",
       "  '009.hdf5',\n",
       "  '021.hdf5',\n",
       "  '053.hdf5',\n",
       "  '029.hdf5',\n",
       "  '057.hdf5',\n",
       "  '055.hdf5',\n",
       "  '040.hdf5',\n",
       "  '051.hdf5',\n",
       "  '033.hdf5',\n",
       "  '056.hdf5',\n",
       "  '043.hdf5',\n",
       "  '004.hdf5',\n",
       "  '020.hdf5',\n",
       "  '048.hdf5',\n",
       "  '002.hdf5'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "files = os.listdir('compiled_dataset')\n",
    "files = list(filter(lambda x: x.endswith('.hdf5'), files))\n",
    "random.shuffle(files)\n",
    "\n",
    "val_files = files[:6]\n",
    "train_files = files[6:]\n",
    "\n",
    "val_files, train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:28<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: Train Loss 0.1007, Val Acc=0.0000, Val Loss=3.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:26<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: Train Loss 0.0467, Val Acc=0.0000, Val Loss=0.0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:25<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: Train Loss 0.0153, Val Acc=0.0000, Val Loss=0.1167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:25<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: Train Loss 0.0153, Val Acc=0.0000, Val Loss=0.1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:24<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: Train Loss 0.0151, Val Acc=0.0000, Val Loss=0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:24<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: Train Loss 0.0150, Val Acc=0.0000, Val Loss=0.1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:23<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: Train Loss 0.0148, Val Acc=0.0000, Val Loss=0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:24<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: Train Loss 0.0149, Val Acc=0.0000, Val Loss=0.1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:31<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: Train Loss 0.0151, Val Acc=0.0000, Val Loss=0.1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:24<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: Train Loss 0.0151, Val Acc=0.0000, Val Loss=0.1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:26<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: Train Loss 0.0151, Val Acc=0.0000, Val Loss=0.1690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:26<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: Train Loss 0.0150, Val Acc=0.0000, Val Loss=0.1687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:31<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: Train Loss 0.0150, Val Acc=0.0000, Val Loss=0.1692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:29<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: Train Loss 0.0150, Val Acc=0.0000, Val Loss=0.1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:28<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: Train Loss 0.0150, Val Acc=0.0000, Val Loss=0.1589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:30<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: Train Loss 0.0150, Val Acc=0.0000, Val Loss=0.1570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:32<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: Train Loss 0.0149, Val Acc=0.0000, Val Loss=0.1526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:30<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: Train Loss 0.0149, Val Acc=0.0000, Val Loss=0.1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:32<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: Train Loss 0.0149, Val Acc=0.0000, Val Loss=0.0978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:33<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: Train Loss 0.0149, Val Acc=0.0000, Val Loss=0.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:31<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: Train Loss 0.0149, Val Acc=0.0000, Val Loss=0.1692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:34<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: Train Loss 0.0149, Val Acc=0.0000, Val Loss=0.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:34<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: Train Loss 0.0149, Val Acc=0.0000, Val Loss=0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:30<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: Train Loss 0.0148, Val Acc=0.0000, Val Loss=0.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [01:32<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: Train Loss 0.0148, Val Acc=0.0000, Val Loss=0.1543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 114/280 [00:42<01:01,  2.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TrackNet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompiled_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m, train_files, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 31\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m instances\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     32\u001b[0m total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m instances\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# print(loss)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val_dataset = TrackNet('compiled_dataset', val_files, debug=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, pin_memory=True, num_workers=6)\n",
    "\n",
    "train_dataset = TrackNet('compiled_dataset', train_files, debug=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, pin_memory=True, num_workers=8)\n",
    "\n",
    "train(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
